

slide(title='Title')

    svg_include(src='svg/title_page.svg')
    // TODO: swap in title text:
    // Machine Learning for Predictive Auto-Tuning with Boosted Regression Trees
    // TODO: swap in author list
    // TODO: swap in date
    // TODO: swap in venue


slide(title='Motivation')
    // TODO: standard bullet slide?
    // code re-use
    // aka libraries
    // maximize speed with JIT but minimize overhead


slide(title='Empirical Auto-tuning')


slide(title='Model-driven Auto-tuning')


slide(title='Best of both worlds')
    // empirical auto-tuning pro con
    // model-driven auto-tuning pro con

    // We want the best of both words.
    // We make use of information that's not being used efficiently by these
    // other techniques.


slide(title='Predictive Auto-tuning')
    //Our way of looking at things is this triangle:
    //- problem features
    //- implementation features
    //- platform features (incl. micro-benchmarks)

    //PREDICTIVE AUTO-TUNING = LEARN A MODEL from timing data.
    // -> data driven and hands-free (like empirical)
    // -> accurate over a large input domain (like model based)


slide(title='Contribution')
    //How are we going to learn the model?

    //Our aim here is to prove the viability of the approach.

    // We present an existance proof: there exists an off-the-shelf learning
    // algorithm (boosted decision trees) that worked in a difficult case that
    // we've been working on.


slide(title='decision trees')


slide(title='boosted decision trees')


slide(title='Mapping autotuning to a regression problem')

    // Log-speedup over reference implementation.

    // How do we deal with invalid configurations?


slide(title='Making use of the learned model')

    //JIT Optimization of the dtree ensemble

    //Backtracking to deal with runtime failures


slide(title='application domain')

    //Sample problem domain: filterbank correlation

    //show cartoon and math


slide(title='application domain 2')

    // Sample problem domain: filterbank correlation

    // implementation and associated options


slide(title='Testing protocol')


slide(title='results1')
    // Results: avg GFLOPs when using the wrong model -> BAD


slide(title='results2')
    // Results: matching empirical auto-tuning -> GOOD


slide(title='results3')
    // Results: how sensitive is the approach to the score of invalid points?


slide(title='summary')
    // Summary



