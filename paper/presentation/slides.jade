
.slide

    h1 Machine Learning for Predictive Auto-Tuning with Boosted Regression Trees

    p Authors: James Bergstra, Nicolas Pinto, David D. Cox
    p Date: May 13, 2012
    p Place: INPAR 2012


.slide

    h1 Desiderata (user)

    ul
        li abstraction barriers beyond which "it just works"
        li fast libs across wide range of GPU devices

    h1 Desiderata (library provider)

    ul
        li [support for providing] fast libs across wide range of GPU devices


.slide

    h1 State of art: How to make a fast function for a GPU

    p as kernel library author we optimize e.g:

    ul
        li blocking strategy
        li global and shared memory layout
        li loop unrolling
        li register spilling
        li global / constant / texture memory
        li registers vs. shared memory

    p joint optimization of all this is HARD


.slide

    h1 State of art: How to make a fast function for a GPU

    p joint optimization of all this is HARD.  Two approaches emerge:

    ul
        li empirical auto-tuning
        li model-driven Tuning


.slide

    h1 State of art: Empirical Auto-tuning

    ul
        li instrument your fn
        li actually run the fn many ways, measure time
        li when installing lib, save pointer to fastest config

    p Pro: very fast implementations

    p Con: what if the input array size changes?

    p Con: what about different hardware revisions / generations?

    p In these cases you're on your own, empirical auto-tuning offers no help.


.slide
    h1 State of Art: Model-Driven Tuning

    ul
        li instrument your fn
        li write a hardware simulator
        li pick fastest config according to simulator

    p Pro: general, high-performance JIT approach

    p Con: who is going to provide simulators for all platforms?


.slide
    h1 Predictive Auto-tuning: Best of both worlds

    ul
        li instrument your /function/
        li instrument your /implementation/
        li instrument your /platform/
        li /measure timing/ as in empirical auto-tuning
        li /fit/ a timing model using machine learning methods


.slide

    h1 Contribution: Proof of Concept

    ul
        li function: filterbank correlation
        li instrumented implementation: [cite]
        li test on several platforms (platform instrumentation is future work)
        li measure timing relative to reference implementation
        li fit boosted regression trees regression model

    p Result: we can match the excellent call-time performance of empirical
    auto-tuning across a range of image and filter sizes without the
    computational cost of empirical auto-tuning.


.slide

    h1 filterbank correlation

    p instance of a stencil computation

    p cartoon and math

    p application domains that care

    p show ranges of problem dimensions, relevance of different cases.


.slide

    h1 filterbank correlation implementation

    p show crazy templated code


.slide

    h1 filterbank correlation implementation

    p list the options that we tuned


.slide

    h1 Mapping timing to a regression problem

    p  Log-speedup over reference implementation.

    p  How do we deal with invalid configurations?



.slide

    h1 regression trees


.slide

    h1 boosted regression trees

    p iteratively fit residuals


.slide

    h1 Making use of the fitted model

    p JIT Optimization of the dtree ensemble with stochastic search "HC75"

    p Backtracking to deal with runtime failures


.slide

    h1 Results: matching empirical auto-tuning -> GOOD


.slide

    h1 Results: avg GFLOPs when using the wrong model -> BAD


.slide

    h1 Results: how sensitive is the approach to the score of invalid points?


.slide

    h1 Summary


.slide

    h1 Future Work

    p platform features: device inspection, micro-benchmarks -> cross-platform
    generalization.


